{"cells":[{"metadata":{"id":"3Tk1dc7Icx31"},"cell_type":"markdown","source":"# Vision Transformer with Knowledge Distillation and LWR\n\nTraining Visual Transformer on *Dogs vs Cats Data*\nReference - https://github.com/lucidrains/vit-pytorch\n"},{"metadata":{"id":"IDT1Xwv9RZXb"},"cell_type":"markdown","source":"## Import Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install vit_pytorch","execution_count":null,"outputs":[]},{"metadata":{"id":"qq-e52uORIVg","trusted":true},"cell_type":"code","source":"from __future__ import print_function\n\nimport glob\nfrom itertools import chain\nimport os\nimport random\nimport zipfile\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom torch.optim.lr_scheduler import StepLR\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import datasets, transforms\nfrom tqdm.notebook import tqdm\n\nfrom vit_pytorch.efficient import ViT\n","execution_count":4,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'vit_pytorch'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-97db0bc117ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvit_pytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mefficient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mViT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'vit_pytorch'"]}]},{"metadata":{"id":"pV-E0IFHRITw","outputId":"4c4b64ce-344d-4de6-f18e-e6c70281e3d1","trusted":true},"cell_type":"code","source":"print(f\"Torch: {torch.__version__}\")","execution_count":null,"outputs":[]},{"metadata":{"id":"GEoNmg0aQVf9","trusted":true},"cell_type":"code","source":"# Training settings\nbatch_size = 16\nepochs = 20\nlr = 3e-5\ngamma = 0.7\nseed = 42","execution_count":null,"outputs":[]},{"metadata":{"id":"mSO-6jwwlYzO","trusted":true},"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_everything(seed)","execution_count":null,"outputs":[]},{"metadata":{"id":"ZS5Jp9SBRgQr","trusted":true},"cell_type":"code","source":"device = 'cuda'","execution_count":null,"outputs":[]},{"metadata":{"id":"ZEIyZaYXRkZF"},"cell_type":"markdown","source":"## Load Data"},{"metadata":{"id":"lvw64WGURgxK","trusted":true},"cell_type":"code","source":"train_dir = 'data/train'\ntest_dir = 'data/test'","execution_count":null,"outputs":[]},{"metadata":{"id":"1hE3h70ZRg2g","outputId":"35c0ab9a-da87-4857-ba08-69032d69dd99","trusted":true},"cell_type":"code","source":"with zipfile.ZipFile('../input/dogs-vs-cats-redux-kernels-edition/train.zip') as train_zip:\n    train_zip.extractall('data')\n    \nwith zipfile.ZipFile('../input/dogs-vs-cats-redux-kernels-edition/test.zip') as test_zip:\n    test_zip.extractall('data')","execution_count":null,"outputs":[]},{"metadata":{"id":"FVD2SEjTRgXh","trusted":true},"cell_type":"code","source":"train_list = glob.glob(os.path.join(train_dir,'*.jpg'))\ntest_list = glob.glob(os.path.join(test_dir, '*.jpg'))","execution_count":null,"outputs":[]},{"metadata":{"id":"GwQ01kgtSExB","trusted":true},"cell_type":"code","source":"print(f\"Train Data: {len(train_list)}\")\nprint(f\"Test Data: {len(test_list)}\")","execution_count":null,"outputs":[]},{"metadata":{"id":"amKHFCu_iwQZ","trusted":true},"cell_type":"code","source":"labels = [path.split('/')[-1].split('.')[0] for path in train_list]","execution_count":3,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'train_list' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-936785f0d13c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'train_list' is not defined"]}]},{"metadata":{"id":"H4NdaHt7R-zP"},"cell_type":"markdown","source":"## Random Plots"},{"metadata":{"id":"Fs8I30iIR6A1","trusted":true},"cell_type":"code","source":"random_idx = np.random.randint(1, len(train_list), size=9)\nfig, axes = plt.subplots(3, 3, figsize=(16, 12))\n\nfor idx, ax in enumerate(axes.ravel()):\n    img = Image.open(train_list[idx])\n    ax.set_title(labels[idx])\n    ax.imshow(img)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"UxHo4dU8SHcZ"},"cell_type":"markdown","source":"## Split"},{"metadata":{"id":"YgrHNTpnR6Hl","trusted":true},"cell_type":"code","source":"train_list, valid_list = train_test_split(train_list, \n                                          test_size=0.2,\n                                          stratify=labels,\n                                          random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"id":"UViq3x5yR5-r","trusted":true},"cell_type":"code","source":"print(f\"Train Data: {len(train_list)}\")\nprint(f\"Validation Data: {len(valid_list)}\")\nprint(f\"Test Data: {len(test_list)}\")","execution_count":null,"outputs":[]},{"metadata":{"id":"ZhYDJXk2SRDu"},"cell_type":"markdown","source":"## Image Augumentation"},{"metadata":{"id":"YKR5RaykR58x","trusted":true},"cell_type":"code","source":"train_transforms = transforms.Compose(\n    [\n        transforms.Resize((224, 224)),\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n    ]\n)\n\nval_transforms = transforms.Compose(\n    [\n        transforms.Resize((224, 224)),\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n    ]\n)\n\n\ntest_transforms = transforms.Compose(\n    [\n        transforms.Resize((224, 224)),\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n    ]\n)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"b0JAXWWtSXpB"},"cell_type":"markdown","source":"## Load Datasets"},{"metadata":{"id":"Ds9yt5kHR56R","trusted":true},"cell_type":"code","source":"class CatsDogsDataset(Dataset):\n    def __init__(self, file_list, transform=None):\n        self.file_list = file_list\n        self.transform = transform\n\n    def __len__(self):\n        self.filelength = len(self.file_list)\n        return self.filelength\n\n    def __getitem__(self, idx):\n        img_path = self.file_list[idx]\n        img = Image.open(img_path)\n        img_transformed = self.transform(img)\n\n        label = img_path.split(\"/\")[-1].split(\".\")[0]\n        label = 1 if label == \"dog\" else 0\n\n        return idx, img_transformed, label\n","execution_count":null,"outputs":[]},{"metadata":{"id":"pC-D9a8xSZNd","trusted":true},"cell_type":"code","source":"train_data = CatsDogsDataset(train_list, transform=train_transforms)\nvalid_data = CatsDogsDataset(valid_list, transform=test_transforms)\ntest_data = CatsDogsDataset(test_list, transform=test_transforms)","execution_count":null,"outputs":[]},{"metadata":{"id":"-mz9qUsLSZVU","trusted":true},"cell_type":"code","source":"train_loader = DataLoader(dataset = train_data, batch_size=batch_size, shuffle=True)\nvalid_loader = DataLoader(dataset = valid_data, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(dataset = test_data, batch_size=batch_size, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"zp6jlEU-_McH"},"cell_type":"markdown","source":"## Model Definition"},{"metadata":{"id":"bGQA0Z3t--XB","trusted":true},"cell_type":"code","source":"from torchvision.models import resnet50\n\nfrom vit_pytorch.distill import DistillableViT, DistillWrapper\n\nteacher = resnet50(pretrained=True)\n\nmodel = DistillableViT(\n    image_size = 224,\n    patch_size = 32,\n    num_classes = 2,\n    dim = 1024,\n    depth = 6,\n    heads = 8,\n    mlp_dim = 2048,\n    dropout = 0.1,\n    emb_dropout = 0.1\n)\n  #check the code","execution_count":null,"outputs":[]},{"metadata":{"id":"z7sh7Zu4JK1k"},"cell_type":"markdown","source":"### **Loss Function**"},{"metadata":{"id":"WTW2C1rqBwhC","trusted":true},"cell_type":"code","source":"\"\"\"\nImplements the knowledge distillation loss --- https://github.com/facebookresearch/deit/blob/main/losses.py\n\"\"\"\nimport torch\nfrom torch.nn import functional as F\n\n\nclass DistillationLoss(nn.Module):\n    \"\"\"\n    This module wraps a standard criterion and adds an extra knowledge distillation loss by\n    taking a teacher model prediction and using it as additional supervision.\n    \"\"\"\n    def __init__(self, base_criterion: torch.nn.Module, teacher_model: torch.nn.Module,\n                 distillation_type: str, alpha: float, tau: float, smoothing, retrospect):\n        super().__init__()\n        self.base_criterion = base_criterion\n        self.teacher_model = teacher_model\n        assert distillation_type in ['none', 'soft', 'hard']\n        self.distillation_type = distillation_type\n        self.alpha = alpha\n        self.tau = tau\n        self.batch_index = None\n        self.smoothing = smoothing\n        self.retrospect = retrospect\n\n    def forward(self, inputs, outputs, labels, batch_index):\n        outputs_kd = None\n        self.batch_index = batch_index\n        \n        if not isinstance(outputs, torch.Tensor):\n            # assume that the model outputs a tuple of [outputs, outputs_kd]\n            outputs, outputs_kd = outputs\n        \n        if self.retrospect:\n            assert self.batch_index!=None\n            base_loss = self.base_criterion(batch_index, outputs, labels)\n            \n        else:\n            base_loss = self.base_criterion(outputs, labels)\n\n\n        if self.distillation_type == 'none':\n            return base_loss\n\n        if outputs_kd is None:\n            raise ValueError(\"When knowledge distillation is enabled, the model is \"\n                             \"expected to return a Tuple[Tensor, Tensor] with the output of the \"\n                             \"class_token and the dist_token\")\n\n        with torch.no_grad():\n            teacher_outputs = self.teacher_model(inputs)\n\n        if self.distillation_type == 'soft':\n            T = self.tau\n\n            distillation_loss = F.kl_div(\n                F.log_softmax(outputs_kd / T, dim=1),\n                F.log_softmax(teacher_outputs / T, dim=1),\n                reduction='sum',\n                log_target=True\n            ) * (T * T) / outputs_kd.numel()\n        elif self.distillation_type == 'hard':\n            distillation_loss = F.cross_entropy(outputs_kd, teacher_outputs.argmax(dim=1))\n\n        loss = base_loss * (1 - self.alpha) + distillation_loss * self.alpha\n        return loss","execution_count":null,"outputs":[]},{"metadata":{"id":"gr7skfK3Od8d","trusted":true},"cell_type":"code","source":"model=model.to(device)\nteacher=teacher.to(device)","execution_count":null,"outputs":[]},{"metadata":{"id":"0BFFqr-4Nsdg","trusted":true},"cell_type":"code","source":"retrospect=True\nsmoothing=False","execution_count":null,"outputs":[]},{"metadata":{"id":"M92K2X9SSQQ3","trusted":true},"cell_type":"code","source":"!pip install timm==0.3.2\nfrom timm.loss import LabelSmoothingCrossEntropy","execution_count":null,"outputs":[]},{"metadata":{"id":"m3DW3sJyO1fO","trusted":true},"cell_type":"code","source":"import numpy as np\nimport torch\nfrom torch import Tensor\nfrom typing import Tuple\nimport torch.nn.functional as F\n\n\ndef soft_crossentropy(logits, y_true, dim):\n    return -1 * (torch.log_softmax(logits, dim=dim) * y_true).sum(axis=1).mean(axis=0)\n\n\ndef crossentropy(logits, y_true, dim):\n    if dim == 1:\n        return F.cross_entropy(logits, y_true)\n    else:\n        loss = 0.\n        for i in range(logits.shape[1]):\n            loss += soft_crossentropy(\n                logits[:, i, :],\n                y_true[:, i, :],\n                dim=1\n            )\n        return loss\n\n\nclass LWR(torch.nn.Module):\n    def __init__(\n        self,\n        k: int,\n        num_batches_per_epoch: int,\n        dataset_length: int,\n        output_shape: Tuple[int],\n        max_epochs: int,\n        tau=5.,\n        update_rate=0.9,\n        softmax_dim=1\n    ):\n        \n        super().__init__()\n        self.k = k\n        self.update_rate = update_rate\n        self.max_epochs = max_epochs\n\n        self.step_count = 0\n        self.epoch_count = 0\n        self.num_batches_per_epoch = num_batches_per_epoch\n\n        self.tau = tau\n        self.alpha = 1.\n\n        self.softmax_dim = softmax_dim\n\n        self.labels = torch.zeros((dataset_length, *output_shape))\n\n    def forward(\n        self,\n        batch_idx: Tensor,\n        logits: Tensor,\n        y_true: Tensor,\n        eval=False\n    ):\n        self.alpha = 1 - self.update_rate * self.epoch_count * self.k / self.max_epochs\n        if self.epoch_count <= self.k:\n            self.step_count += 1\n            if (self.step_count + 1) % self.num_batches_per_epoch == 0 and eval is False:\n                self.step_count = 0\n                self.epoch_count += 1\n\n            if self.epoch_count == self.k and eval is False:\n                # print(self.labels[batch_idx, ...].shape, logits.shape)\n                self.labels[batch_idx, ...] = torch.softmax(\n                    logits / self.tau, dim=self.softmax_dim).detach().clone().cpu()\n            return F.cross_entropy(logits, y_true)\n        else:\n            if (self.epoch_count + 1) % self.k == 0 and eval is False:\n                self.labels[batch_idx, ...] = torch.softmax(\n                    logits / self.tau, dim=self.softmax_dim).detach().clone().cpu()\n            return self.loss_fn_with_kl(logits, y_true, batch_idx)\n\n    def loss_fn_with_kl(\n        self,\n        logits: Tensor,\n        y_true: Tensor,\n        batch_idx: Tensor,\n    ):\n\n        return self.alpha * crossentropy(logits, y_true, dim=self.softmax_dim) +\\\n            (1 - self.alpha) * self.tau * self.tau *\\\n            F.kl_div(\n                F.log_softmax(logits / self.tau, dim=self.softmax_dim),\n                self.labels[batch_idx, ...].to(logits.get_device()),\n                reduction='batchmean'\n        )","execution_count":null,"outputs":[]},{"metadata":{"id":"JCP4pvWFDmDv","trusted":true},"cell_type":"code","source":"smoothing = False\nretrospect = True\n\nvalue = 0.1 \nif smoothing : \n    base_criterion = LabelSmoothingCrossEntropy(smoothing = value)\n    \nelif retrospect: \n    base_criterion = LWR(\n    k=3,\n    update_rate=0.9,\n    num_batches_per_epoch=len(train_data) // batch_size,\n    dataset_length=len(train_data),\n    output_shape=(2, ),\n    tau=5,\n    max_epochs=20,\n    softmax_dim=1\n)\n      \nelse : \n    base_criterion = nn.CrossEntropyLoss()\n\ncriterion = DistillationLoss(\n    base_criterion, teacher, 'none', 0.5, 1.0, smoothing, retrospect)","execution_count":null,"outputs":[]},{"metadata":{"id":"9OXHnGR-Dl2b","trusted":true},"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(), lr=lr)\nscheduler = StepLR(optimizer, step_size=1, gamma=gamma)  ","execution_count":null,"outputs":[]},{"metadata":{"id":"Aj3_9laUQIUg"},"cell_type":"markdown","source":"## Training loop"},{"metadata":{"id":"3NQxXY8h--RH","trusted":true},"cell_type":"code","source":"for epoch in range(epochs):\n    epoch_loss = 0\n    epoch_accuracy = 0\n\n    for batch_idx, data, label in tqdm(train_loader):\n        data = data.to(device)\n        label = label.to(device)\n\n        output = model(data).to(device)\n        loss = criterion(data, output, label, batch_idx)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        acc = (output.argmax(dim=1) == label).float().mean()\n        epoch_accuracy += acc / len(train_loader)\n        epoch_loss += loss / len(train_loader)\n        batch_idx+=1\n\n    with torch.no_grad():\n        epoch_val_accuracy = 0\n        epoch_val_loss = 0\n\n        for val_batch_idx, data, label in valid_loader:\n            data = data.to(device)\n            label = label.to(device)\n\n            val_output = model(data).to(device)\n            val_loss = criterion(data, val_output, label, val_batch_idx)\n\n            acc = (val_output.argmax(dim=1) == label).float().mean()\n            epoch_val_accuracy += acc / len(valid_loader)\n            epoch_val_loss += val_loss / len(valid_loader)\n\n    print(\n        f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f} - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\"\n    )\n","execution_count":null,"outputs":[]},{"metadata":{"id":"4u5YZG1eozIv"},"cell_type":"markdown","source":"### Save weights"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntorch.save(model.state_dict(), 'ViT_LWR.pth')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}